{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(\"testdata_manual_2009_06_14.csv\", names=['Depression_Level','SNo','PostDate','Source','Destination','Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depression_Level</th>\n",
       "      <th>SNo</th>\n",
       "      <th>PostDate</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Depression_Level  SNo                      PostDate   Source Destination  \\\n",
       "0                 4    3  Mon May 11 03:17:40 UTC 2009  kindle2      tpryan   \n",
       "1                 4    4  Mon May 11 03:18:03 UTC 2009  kindle2      vcu451   \n",
       "2                 4    5  Mon May 11 03:18:54 UTC 2009  kindle2      chadfu   \n",
       "3                 4    6  Mon May 11 03:19:04 UTC 2009  kindle2       SIX15   \n",
       "4                 4    7  Mon May 11 03:21:41 UTC 2009  kindle2    yamarama   \n",
       "\n",
       "                                               Tweet  \n",
       "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...  \n",
       "1  Reading my kindle2...  Love it... Lee childs i...  \n",
       "2  Ok, first assesment of the #kindle2 ...it fuck...  \n",
       "3  @kenburbary You'll love your Kindle2. I've had...  \n",
       "4  @mikefish  Fair enough. But i have the Kindle2...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing NLP Text Preprocessing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An alternative library of English stop-words in \"sklearn\" library rather than 'nklt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'may', 'was', 'thereafter', 'or', 'for', 'amongst', 'around', 'etc', 'my', 'are', 'always', 'as', 'then', 'her', 'six', 'myself', 'third', 'again', 'during', 'everywhere', 'made', 'once', 'therein', 'thereupon', 'than', 'whether', 'until', 'both', 'former', 'these', 'nor', 'against', 'bottom', 'alone', 'herein', 'his', 'side', 'it', 'own', 'every', 'you', 'beforehand', 'thick', 'hers', 'less', 'seemed', 'down', 'perhaps', 'hasnt', 'seem', 'be', 'sometimes', 'any', 'do', 'might', 'many', 'he', 'among', 'de', 'elsewhere', 'something', 'me', 'should', 'himself', 'ltd', 'thence', 'anyone', 'have', 'thin', 'per', 'several', 'very', 'toward', 'all', 'enough', 'top', 'fire', 'front', 'must', 'done', 'afterwards', 'of', 'not', 'three', 'mine', 'un', 'whereas', 'being', 'else', 'an', 'indeed', 'sixty', 'couldnt', 'others', 'those', 'there', 'towards', 'within', 'con', 'under', 'even', 'they', 'themselves', 'two', 'anywhere', 'together', 'besides', 'throughout', 'most', 'ourselves', 'becomes', 'into', 'mostly', 'without', 'well', 'them', 'please', 'what', 'above', 'becoming', 'eleven', 'since', 'yourselves', 'last', 'never', 'could', 'mill', 'such', 'too', 'twelve', 'who', 'at', 'next', 'seems', 'give', 'find', 'describe', 'became', 'somehow', 'still', 'would', 'found', 'nine', 'wherein', 'below', 'hundred', 'on', 'also', 'before', 'where', 'move', 'no', 'along', 'anyhow', 'amoungst', 'five', 'she', 'twenty', 'yours', 'so', 'go', 'and', 'beside', 'sometime', 'rather', 'fifteen', 'now', 'whereupon', 'about', 'latterly', 'a', 'nobody', 'almost', 'because', 'thru', 'when', 'however', 'more', 'due', 'in', 'amount', 'anyway', 'had', 'its', 'we', 'while', 'sincere', 'through', 'hence', 'can', 'after', 'further', 'whence', 'beyond', 'thus', 'off', 're', 'will', 'inc', 'detail', 'take', 'keep', 'up', 'name', 'least', 'hereupon', 'but', 'whither', 'herself', 'out', 'therefore', 'none', 'show', 'somewhere', 'yourself', 'onto', 'co', 'anything', 'latter', 'though', 'namely', 'is', 'four', 'yet', 'formerly', 'first', 'nevertheless', 'already', 'were', 'forty', 'upon', 'seeming', 'has', 'this', 'another', 'nothing', 'i', 'except', 'part', 'if', 'one', 'by', 'otherwise', 'with', 'empty', 'hereby', 'fifty', 'to', 'ours', 'get', 'how', 'our', 'fill', 'same', 'him', 'behind', 'whereafter', 'nowhere', 'been', 'everyone', 'someone', 'whatever', 'why', 'itself', 'back', 'moreover', 'put', 'everything', 'ten', 'few', 'over', 'their', 'often', 'whole', 'eg', 'your', 'interest', 'whoever', 'cannot', 'thereby', 'only', 'here', 'bill', 'some', 'wherever', 'which', 'whose', 'become', 'across', 'cry', 'much', 'neither', 'between', 'noone', 'serious', 'that', 'full', 'hereafter', 'am', 'us', 'call', 'system', 'other', 'see', 'via', 'either', 'each', 'cant', 'meanwhile', 'ie', 'from', 'whenever', 'ever', 'eight', 'whom', 'whereby', 'although', 'the'}\n"
     ]
    }
   ],
   "source": [
    "print(set(ENGLISH_STOP_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ds.Tweet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.\n"
     ]
    }
   ],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample text Cleaning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Preprocessing: ...\n",
      " @stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.\n",
      "\n",
      "Removed special characters and numbers: ... \n",
      " ['stellargirl', 'i', 'loooooooovvvvvveee', 'my', 'kindle', 'not', 'that', 'the', 'dx', 'is', 'cool', 'but', 'the', 'is', 'fantastic', 'in', 'its', 'own', 'right']\n",
      "\n",
      "Stemmed and removed common words: ... \n",
      " stellargirl loooooooovvvvvvee kindl dx cool fantast right\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Preprocessing: ...\\n\", ds.Tweet[0])\n",
    "\n",
    "# Removing all numbers, punctuations and special characters. Extract only alphabets\n",
    "tweet = re.sub('[^a-zA-Z]',' ', ds.Tweet[0])\n",
    "\n",
    "# Converting all text to lowercase\n",
    "tweet = tweet.lower()\n",
    "tweet = tweet.split()\n",
    "print('\\nRemoved special characters and numbers: ... \\n', tweet)\n",
    "\n",
    "\n",
    "# Stemming (Using only the root word of every polymorphic words. e.g. Loved, Loving = Love; Eat, Ate, Eaten = Eat; etc)\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Removing all common words e.g. Preposition, article, conjunction, etc.\n",
    "#tweet = [ps.stem(word) for word in tweet if word not in set(stopwords.words('english'))]\n",
    "tweet = [ps.stem(word) for word in tweet if word not in set(ENGLISH_STOP_WORDS)]\n",
    "tweet = ' '.join(tweet)\n",
    "print('\\nStemmed and removed common words: ... \\n', tweet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Text Cleaning and creating of Corpus of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ds.index)):\n",
    "    # Removing all numbers, punctuations and special characters. Extract only alphabets\n",
    "    tweet = re.sub('[^a-zA-Z]',' ', ds.Tweet[i])\n",
    "\n",
    "    # Converting all text to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.split()\n",
    "\n",
    "    # Stemming (Using only the root word of every polymorphic words. e.g. Loved, Loving = Love; Eat, Ate, Eaten = Eat; etc)\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    # Removing all common words e.g. Preposition, article, conjunction, etc.\n",
    "    tweet = [ps.stem(word) for word in tweet if word not in set(ENGLISH_STOP_WORDS)]\n",
    "    tweet = ' '.join(tweet)\n",
    "    \n",
    "    # Creating Corpus of tweets\n",
    "    corpus.append(tweet)\n",
    "    \n",
    "\n",
    "ds['Cleaned Tweet'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depression_Level</th>\n",
       "      <th>SNo</th>\n",
       "      <th>PostDate</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Cleaned Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "      <td>stellargirl loooooooovvvvvvee kindl dx cool fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "      <td>read kindl love lee child good read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "      <td>ok asses kindl fuck rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "      <td>kenburbari ll love kindl ve month look new big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "      <td>mikefish fair kindl think s perfect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Depression_Level  SNo                      PostDate   Source Destination  \\\n",
       "0                 4    3  Mon May 11 03:17:40 UTC 2009  kindle2      tpryan   \n",
       "1                 4    4  Mon May 11 03:18:03 UTC 2009  kindle2      vcu451   \n",
       "2                 4    5  Mon May 11 03:18:54 UTC 2009  kindle2      chadfu   \n",
       "3                 4    6  Mon May 11 03:19:04 UTC 2009  kindle2       SIX15   \n",
       "4                 4    7  Mon May 11 03:21:41 UTC 2009  kindle2    yamarama   \n",
       "\n",
       "                                               Tweet  \\\n",
       "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...   \n",
       "1  Reading my kindle2...  Love it... Lee childs i...   \n",
       "2  Ok, first assesment of the #kindle2 ...it fuck...   \n",
       "3  @kenburbary You'll love your Kindle2. I've had...   \n",
       "4  @mikefish  Fair enough. But i have the Kindle2...   \n",
       "\n",
       "                                       Cleaned Tweet  \n",
       "0  stellargirl loooooooovvvvvvee kindl dx cool fa...  \n",
       "1                read kindl love lee child good read  \n",
       "2                           ok asses kindl fuck rock  \n",
       "3  kenburbari ll love kindl ve month look new big...  \n",
       "4                mikefish fair kindl think s perfect  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tweet\n",
      "---------------\n",
      "@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.\n",
      "\n",
      "\n",
      "Cleaned Tweet\n",
      "---------------\n",
      "stellargirl loooooooovvvvvvee kindl dx cool fantast right\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Tweet\")\n",
    "print('---------------')\n",
    "print(ds.Tweet[0])\n",
    "print('\\n')\n",
    "\n",
    "print(\"Cleaned Tweet\")\n",
    "print('---------------')\n",
    "print(ds['Cleaned Tweet'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Bag of words model (Sparse Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=1000)\n",
    "bag_of_words = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = pd.DataFrame(bag_of_words, index=ds.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   994  995  996  997  998  999  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = pd.concat([ds.drop(['Tweet', 'Cleaned Tweet'], axis=1), bag_of_words], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depression_Level</th>\n",
       "      <th>SNo</th>\n",
       "      <th>PostDate</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Depression_Level  SNo                      PostDate   Source Destination  \\\n",
       "0                 4    3  Mon May 11 03:17:40 UTC 2009  kindle2      tpryan   \n",
       "1                 4    4  Mon May 11 03:18:03 UTC 2009  kindle2      vcu451   \n",
       "2                 4    5  Mon May 11 03:18:54 UTC 2009  kindle2      chadfu   \n",
       "\n",
       "   0  1  2  3  4  ...  990  991  992  993  994  995  996  997  998  999  \n",
       "0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "1  0  0  0  0  0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "2  0  0  0  0  0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[3 rows x 1005 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depression_Level</th>\n",
       "      <th>SNo</th>\n",
       "      <th>PostDate</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4</td>\n",
       "      <td>14074</td>\n",
       "      <td>Sun Jun 14 04:36:34 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>iamtheonlyjosie</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>14075</td>\n",
       "      <td>Sun Jun 14 21:36:07 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>plutopup7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>14076</td>\n",
       "      <td>Sun Jun 14 21:36:17 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>captain_pete</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Depression_Level    SNo                      PostDate Source  \\\n",
       "495                 4  14074  Sun Jun 14 04:36:34 UTC 2009  latex   \n",
       "496                 0  14075  Sun Jun 14 21:36:07 UTC 2009   iran   \n",
       "497                 0  14076  Sun Jun 14 21:36:17 UTC 2009   iran   \n",
       "\n",
       "         Destination  0  1  2  3  4  ...  990  991  992  993  994  995  996  \\\n",
       "495  iamtheonlyjosie  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "496        plutopup7  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "497     captain_pete  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "\n",
       "     997  998  999  \n",
       "495    0    0    0  \n",
       "496    0    0    0  \n",
       "497    0    0    0  \n",
       "\n",
       "[3 rows x 1005 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Depression_Level    0\n",
       "SNo                 0\n",
       "PostDate            0\n",
       "Source              0\n",
       "Destination         0\n",
       "                   ..\n",
       "995                 0\n",
       "996                 0\n",
       "997                 0\n",
       "998                 0\n",
       "999                 0\n",
       "Length: 1005, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    182\n",
       "0    177\n",
       "2    139\n",
       "Name: Depression_Level, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2.Depression_Level.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Dataset into Training and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bag_of_words\n",
    "y = ds.Depression_Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    ...  990  991  992  \\\n",
       "265    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "448    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "     993  994  995  996  997  998  999  \n",
       "265    0    0    0    0    0    0    0  \n",
       "448    0    0    0    0    0    0    0  \n",
       "\n",
       "[2 rows x 1000 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265    4\n",
       "448    2\n",
       "Name: Depression_Level, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train (448, 1000)\n",
      "Shape of X_test (50, 1000)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train', X_train.shape)\n",
    "print('Shape of X_test', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_prediction = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_predictions = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param = {'n_neighbors': list(range(2,50))}\n",
    "grid_knn = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=knn_param, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'n_neighbors': 23}\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters: ', grid_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_predictions = grid_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, r2_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB\n",
      "----------\n",
      "[[11  1  3]\n",
      " [ 0 12  5]\n",
      " [ 2  8  8]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.73      0.79        15\n",
      "          2       0.57      0.71      0.63        17\n",
      "          4       0.50      0.44      0.47        18\n",
      "\n",
      "avg / total       0.63      0.62      0.62        50\n",
      "\n",
      "-0.03595368677635591\n",
      "0.62\n",
      "\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "--------------\n",
      "[[ 9  2  4]\n",
      " [ 2 11  4]\n",
      " [ 2  4 12]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.60      0.64        15\n",
      "          2       0.65      0.65      0.65        17\n",
      "          4       0.60      0.67      0.63        18\n",
      "\n",
      "avg / total       0.64      0.64      0.64        50\n",
      "\n",
      "-0.09689213893967086\n",
      "0.64\n",
      "\n",
      "\n",
      "\n",
      "KNN\n",
      "---\n",
      "[[ 5  5  5]\n",
      " [ 1 10  6]\n",
      " [ 0  7 11]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.33      0.48        15\n",
      "          2       0.45      0.59      0.51        17\n",
      "          4       0.50      0.61      0.55        18\n",
      "\n",
      "avg / total       0.58      0.52      0.52        50\n",
      "\n",
      "-0.1882998171846435\n",
      "0.52\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('GaussianNB')\n",
    "print('----------')\n",
    "print(confusion_matrix(y_test, nb_prediction))\n",
    "print(classification_report(y_test, nb_prediction))\n",
    "print(r2_score(y_test, nb_prediction))\n",
    "print(accuracy_score(y_test, nb_prediction))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Decision Tree')\n",
    "print('--------------')\n",
    "print(confusion_matrix(y_test, dtree_predictions))\n",
    "print(classification_report(y_test, dtree_predictions))\n",
    "print(r2_score(y_test, dtree_predictions))\n",
    "print(accuracy_score(y_test, dtree_predictions))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('KNN')\n",
    "print('---')\n",
    "print(confusion_matrix(y_test, knn_predictions))\n",
    "print(classification_report(y_test, knn_predictions))\n",
    "print(r2_score(y_test, knn_predictions))\n",
    "print(accuracy_score(y_test, knn_predictions))\n",
    "print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Using Dimensionality Reduction Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensioality Reduction Techniques\n",
    "    Most Used Techniques are PCA, LDA, and Kernel PCA:\n",
    "    Principal Component Analysis (PCA): \n",
    "        Uses the features that with higher explained variance. \n",
    "        It does not considers the dependent ,y, variable and as such is called UnSupervised Dim. Reduction Method \n",
    "        \n",
    "    Linear Discriminant Analysis (LDA):\n",
    "        Uses the features that most separates the classes of the dependent, y, variable.\n",
    "        It uses the dependent variable classes, so it is a Supervised Dim. Reduction Method\n",
    "        \n",
    "    Kernel PCA:\n",
    "        Advanced form of PCA used for Non-Linearly Separable dataset, when the X and y do not have a linear relationship\n",
    "        Used when there are many dimensionality involved.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis \n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set theis first and then change the value of n_components arg. to 'None' and then change, \n",
    "# after testing the explained variance. \n",
    "# pca = PCA(n_components=None) .......Firstly\n",
    "\n",
    "pca = PCA(n_components=400)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9958738341068587"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance[:450].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_prediction = nb.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_predictions = dtree.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param = {'n_neighbors': list(range(2,50))}\n",
    "grid_knn = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=knn_param, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_knn.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'n_neighbors': 24}\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters: ', grid_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_predictions = grid_knn.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, r2_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB\n",
      "----------\n",
      "[[ 6  3  6]\n",
      " [ 0  6 11]\n",
      " [ 2  3 13]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.40      0.52        15\n",
      "          2       0.50      0.35      0.41        17\n",
      "          4       0.43      0.72      0.54        18\n",
      "\n",
      "avg / total       0.55      0.50      0.49        50\n",
      "\n",
      "-0.4929920780012187\n",
      "0.5\n",
      "\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "--------------\n",
      "[[ 9  5  1]\n",
      " [ 2  8  7]\n",
      " [ 4  4 10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.60      0.60        15\n",
      "          2       0.47      0.47      0.47        17\n",
      "          4       0.56      0.56      0.56        18\n",
      "\n",
      "avg / total       0.54      0.54      0.54        50\n",
      "\n",
      "-0.15783059110298603\n",
      "0.54\n",
      "\n",
      "\n",
      "\n",
      "KNN\n",
      "---\n",
      "[[ 4  6  5]\n",
      " [ 0 12  5]\n",
      " [ 0 13  5]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.27      0.42        15\n",
      "          2       0.39      0.71      0.50        17\n",
      "          4       0.33      0.28      0.30        18\n",
      "\n",
      "avg / total       0.55      0.42      0.41        50\n",
      "\n",
      "-0.3406459475929311\n",
      "0.42\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('GaussianNB')\n",
    "print('----------')\n",
    "print(confusion_matrix(y_test, nb_prediction))\n",
    "print(classification_report(y_test, nb_prediction))\n",
    "print(r2_score(y_test, nb_prediction))\n",
    "print(accuracy_score(y_test, nb_prediction))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Decision Tree')\n",
    "print('--------------')\n",
    "print(confusion_matrix(y_test, dtree_predictions))\n",
    "print(classification_report(y_test, dtree_predictions))\n",
    "print(r2_score(y_test, dtree_predictions))\n",
    "print(accuracy_score(y_test, dtree_predictions))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('KNN')\n",
    "print('---')\n",
    "print(confusion_matrix(y_test, knn_predictions))\n",
    "print(classification_report(y_test, knn_predictions))\n",
    "print(r2_score(y_test, knn_predictions))\n",
    "print(accuracy_score(y_test, knn_predictions))\n",
    "print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# Set theis first and then change the value of n_components arg. to 'None' and then change, \n",
    "# after testing the explained variance. \n",
    "# pca = PCA(n_components=None) .......Firstly\n",
    "\n",
    "lda = LDA(n_components=400)\n",
    "X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "X_test_lda = lda.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train_lda,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_prediction = nb.predict(X_test_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X_train_lda,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_predictions = dtree.predict(X_test_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param = {'n_neighbors': list(range(2,50))}\n",
    "grid_knn = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=knn_param, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_knn.fit(X_train_lda, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters: ', grid_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_predictions = grid_knn.predict(X_test_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, r2_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB\n",
      "----------\n",
      "[[6 6 3]\n",
      " [3 9 5]\n",
      " [3 8 7]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.40      0.44        15\n",
      "          2       0.39      0.53      0.45        17\n",
      "          4       0.47      0.39      0.42        18\n",
      "\n",
      "avg / total       0.45      0.44      0.44        50\n",
      "\n",
      "-0.40158439975624627\n",
      "0.44\n",
      "\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "--------------\n",
      "[[6 4 5]\n",
      " [3 7 7]\n",
      " [5 5 8]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.40      0.41        15\n",
      "          2       0.44      0.41      0.42        17\n",
      "          4       0.40      0.44      0.42        18\n",
      "\n",
      "avg / total       0.42      0.42      0.42        50\n",
      "\n",
      "-0.7976843388177941\n",
      "0.42\n",
      "\n",
      "\n",
      "\n",
      "KNN\n",
      "---\n",
      "[[ 6  6  3]\n",
      " [ 3 10  4]\n",
      " [ 4  8  6]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.40      0.43        15\n",
      "          2       0.42      0.59      0.49        17\n",
      "          4       0.46      0.33      0.39        18\n",
      "\n",
      "avg / total       0.45      0.44      0.43        50\n",
      "\n",
      "-0.4929920780012187\n",
      "0.44\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('GaussianNB')\n",
    "print('----------')\n",
    "print(confusion_matrix(y_test, nb_prediction))\n",
    "print(classification_report(y_test, nb_prediction))\n",
    "print(r2_score(y_test, nb_prediction))\n",
    "print(accuracy_score(y_test, nb_prediction))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Decision Tree')\n",
    "print('--------------')\n",
    "print(confusion_matrix(y_test, dtree_predictions))\n",
    "print(classification_report(y_test, dtree_predictions))\n",
    "print(r2_score(y_test, dtree_predictions))\n",
    "print(accuracy_score(y_test, dtree_predictions))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('KNN')\n",
    "print('---')\n",
    "print(confusion_matrix(y_test, knn_predictions))\n",
    "print(classification_report(y_test, knn_predictions))\n",
    "print(r2_score(y_test, knn_predictions))\n",
    "print(accuracy_score(y_test, knn_predictions))\n",
    "print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Principal Component Analysis (Kernel PCA)\n",
    "    Used for Linearly Inseparable Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis \n",
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set theis first and then change the value of n_components arg. to 'None' and then change, \n",
    "# after testing the explained variance. \n",
    "# pca = PCA(n_components=None) .......Firstly\n",
    "\n",
    "kpca = KernelPCA(n_components=400, kernel='rbf')\n",
    "X_train_kpca = kpca.fit_transform(X_train)\n",
    "X_test_kpca = kpca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train_kpca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_prediction = nb.predict(X_test_kpca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X_train_kpca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_predictions = dtree.predict(X_test_kpca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param = {'n_neighbors': list(range(2,50))}\n",
    "grid_knn = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=knn_param, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_knn.fit(X_train_kpca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'n_neighbors': 24}\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters: ', grid_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_predictions = grid_knn.predict(X_test_kpca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, r2_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB\n",
      "----------\n",
      "[[ 8  0  7]\n",
      " [ 0  3 14]\n",
      " [ 2  2 14]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.53      0.64        15\n",
      "          2       0.60      0.18      0.27        17\n",
      "          4       0.40      0.78      0.53        18\n",
      "\n",
      "avg / total       0.59      0.50      0.47        50\n",
      "\n",
      "-0.5843997562461913\n",
      "0.5\n",
      "\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "--------------\n",
      "[[ 7  5  3]\n",
      " [ 1  9  7]\n",
      " [ 2  6 10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.47      0.56        15\n",
      "          2       0.45      0.53      0.49        17\n",
      "          4       0.50      0.56      0.53        18\n",
      "\n",
      "avg / total       0.54      0.52      0.52        50\n",
      "\n",
      "-0.1882998171846435\n",
      "0.52\n",
      "\n",
      "\n",
      "\n",
      "KNN\n",
      "---\n",
      "[[ 5  6  4]\n",
      " [ 0 12  5]\n",
      " [ 0 13  5]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50        15\n",
      "          2       0.39      0.71      0.50        17\n",
      "          4       0.36      0.28      0.31        18\n",
      "\n",
      "avg / total       0.56      0.44      0.43        50\n",
      "\n",
      "-0.21876904326630098\n",
      "0.44\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('GaussianNB')\n",
    "print('----------')\n",
    "print(confusion_matrix(y_test, nb_prediction))\n",
    "print(classification_report(y_test, nb_prediction))\n",
    "print(r2_score(y_test, nb_prediction))\n",
    "print(accuracy_score(y_test, nb_prediction))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Decision Tree')\n",
    "print('--------------')\n",
    "print(confusion_matrix(y_test, dtree_predictions))\n",
    "print(classification_report(y_test, dtree_predictions))\n",
    "print(r2_score(y_test, dtree_predictions))\n",
    "print(accuracy_score(y_test, dtree_predictions))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('KNN')\n",
    "print('---')\n",
    "print(confusion_matrix(y_test, knn_predictions))\n",
    "print(classification_report(y_test, knn_predictions))\n",
    "print(r2_score(y_test, knn_predictions))\n",
    "print(accuracy_score(y_test, knn_predictions))\n",
    "print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
